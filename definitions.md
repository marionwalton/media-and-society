---
layout: home
title: 13. Definitions for Media & Society
---

Use this page to keep track of the new concepts you are learning in *Media & Society*. 

## media keywords

You should generally avoid using regular dictionaries 
to find the meaning of *academic keywords*. 
Academic keywords have specialised meanings based in a particular area of study, and so their definition
may be quite different to how the word is used in everyday language. 
*Your readings have been carefully chosen to provide all the important definitions and explanations that you'll need in this course*.
Where the definitions aren't included in your readings, you should find them below.


## Table of Contents

[Artificial Intelligence](#artificial_intelligence)

[AI Generated Content](#ai_generated_content)

[Artificial General Intelligence](#artificial_general_intelligence)

[Cultural Imperialism](#cultural_imperialism)

[Diffusion Model](#diffusion_model)

[Digital Inequality](#digital_inequality)

[Biased models](#biased_models)

[Language Model](#language_model)

[Large Language Model](#large_language_model)

[Mass Media](#mass_media)

[Machine Learning](#machine_learning)

[Media Practices](#media_practices)

[Model](#model)

[Social Media](#social_media)

[Synthetic Media](#synthetic_media)

[Training data](#training_data)

<a name="affordance"></a> 
### Affordance
An affordance of a mode of communication is what it is possible to express and represent or communicate easily with 
the resources of a mode, and what is less straightforward or even impossible. Thus all modes of communication
have potential and constraints. 

<a name="algorithm"></a> 
### Algorithm
An algorithm is a  set of rules that are followed in calculations and other problems. Contemporary cameras and 
apps such as Instagram and TikTok include graphical algorithms ("filters") which can create certain visual effects ("beautifying", blurring etc).
On social media platforms common algorithms include **editorial tasks** such as sorting, recommendations, content moderation and so on. 
Generative AI systems are also algorithms, so that for example LLMs are essentially deep learning algorithms
that perform a range of natural language processing (NLP) tasks.
The algorithms of Generative AI systems can also be set up to avoid producing certain kinds of content present in the training data or responding to 
certain types of prompts, which can be seen as a new form of **content moderation** or **censorship**. 

<a name="artificial_intelligence"></a> 
### Artificial Intelligence or AI  

Artificial intelligence is an academic field with a 60 year history but the term does not have a generally 
accepted definition. The term “artificial intelligence” is more often used by marketers than researchers, and 
broadly refers to machines “acting like humans”, or passing the Turing test, where a human would not be able to 
distinguish a machine from a human in conversation (Verdegem, 2021:4). Apart from its scientific meanings, the 
term “artificial intelligence” is also currently used by the tech industry as part of a wave of marketing hype 
intended to sell a range of software products which often promise to reduce costs or increase speed by automating 
various human tasks. These are versatile tools with a range of possible uses, but are currently not reliable, and
can be biased. 

Artificial intelligence is not actual intelligence. It may even be possible that use of the word “intelligence” 
here reflects our tendency to anthropomorphise AI (Salles, Evers, & Farisco, 2020). More precisely, AI refers to 
the ways in which we use computer programmes to build neural network models that can automate certain tasks for us.

<a name="artificial_general_intelligence"></a> 
### AGI or Artificial General Intelligence 
This idea of a godlike (or malevolent) superintelligence lies somewhere between science fiction and fantasy. 
It definitely does not exist yet.

<a name="biased_models"></a> 
### Biased models 
We use AI models to undertake analysis, such as classifying the objects or people represented in a digital image. 
In this way Google Photos is able to predict which of your photographs include images of your various friends and 
family, or Meta predicts which content posted to a social media site might be offensive to its users. 

At the same time, if the model has not been trained on enough examples of a particular kind, it is unlikely to be able
to identify those examples in new data. As a result of this kind of bias in training data, machine vision systems were
not able to recognise Black people’s faces - a problem explored by Joy Buolamwini in the documentary *Coded Bias* 
(Coded Bias. 2020).

AI models can also be used to automate decisions. Such models are used to make a decision along the lines of previous 
similar decisions. For example, AI recruiting tools have been used to predict whether someone’s CV suggests they would
be a good employee. These tools work by comparing the applicant’s CV to a model trained on the CVs of previous 
successful applicants. While this might help to address some unfair hiring practices (e.g. nepotism when people hire
their family and friends), it also means that such systems also perpetuate discriminatory patterns present in the 
training data - such as a predominance of male employees, for example. 

Finally, generative models are used to automate media production. They generate media, such as text, image, or audio 
by synthesising it from a large number of examples of similar media. If there are not many examples of a certain type of
text or image in its training data, it is not likely to be able to generate them.

<a name="chatbot"></a>
### Chatbot
Contemporary Generative AI systems are connected to a chatbot interface, which allows users to ask questions via text or speech interfaces and then uses 
statistical models to predict and synthesize a likely "answer" to the user's prompt. By simulating "typing" and "thinking", the interface often encourages
users to humanise or **anthropomorphise** the system (as do terms such as "intelligence" and "training") 
as a when it is really simply a new form of **automation**.

<a name="diffusion_model"></a> 
### Diffusion model 
A model which has been trained on a large collection of images that are “diffused” into and out of random noise. 
This “teaches” the model to see images in noise and generate them from scratch. Almost every major image-generating 
AI model on the market today is a diffusion model. Examples of such AI systems include Midjourney, DALL-E (ChatGPT’s 
image generator), Stable Diffusion and Imagen.

### Digital inequality
Digital inequality (also known as the digital divide) refers to the differences in use of digital technology and services by 
different groups of people. People's socio-economic status, age, gender and race can all mean that they have fewer opportunities 
to benefit from and enjoy using digital media.

<a name="generative_ai"></a> 
### Generative AI, GenAI or AI generated content 
Generative AI, or GenAI refer to generative models such as LLMs or diffusion models used as media production tools are leading to dramatic shifts in both 
professional and everyday media practices. Four tech companies, namely Alphabet (Google), Amazon, Microsoft and Meta (Facebook) have recently 
invested billions of dollars in their respective Artificial Intelligence (AI) systems which will have major consequences
for the media production ecosystem. GenAI AIGC (Artificial Intelligence generated content) is already being incorporated in a wide
range of image editing and graphic design software (e.g. Adobe, Canva) as well as short form video production apps
for social platforms (e.g. Douyin/TikTok). The use of generative models to produce 
media raises various ethical issues and is facing several legal challenges. 

<a name="model"></a> 
### Model 
The purpose of an AI system is to model the world through data in order to predict something about it. The model 
is what makes the AI work. In the case of generative AI, mathematical models of a type of media are produced (text, 
images or audio). These models can be used to produce synthetic media. The model is a collection of statistics which
represent patterns in the training dataset of media using an artificial neural network (see definition) along with software
needed to use the network. Contemporary large language models can generate seemingly fluent articles by determining a most likely 
sequence of words to respond to a prompt, they can perform limited reasoning tasks as long as the training data
includes text descriptions of similar tasks.

Using an AI model to predict something is similar to activities we do every day, such as when we look out at the 
weather to predict what clothes we should select for the day. We can do this because we have a mental model of how 
the weather works, which can be very useful to us. Sometimes, however, this model is wrong and we make an incorrect 
prediction. Similarly, statistical models approximate reality but are never exactly accurate.

<a name="language_model"></a> 
### LM or Language Model 
Language Models (LM) are trained on text, and tend to be specialised. 

<a name="large_language_model"></a> <a name="llm"></a>
### LLM or Large Language Model 
Large Language Models include OpenAI’s ChatGPT, Google’s Gemini (previously Bard) and Meta’s Llama. LLMs are able to
generate lengthy plausible sounding text answers and simulate convincing conversations fluently. 

<a name="machine_learning"></a> 
### Machine Learning 
Most contemporary uses of the term AI actually refer to Machine Learning.  Machine Learning is a subfield of AI 
which identifies patterns in data in order to use them for prediction. The word “learning” is used to refer to the 
way these systems can produce outputs which have not been explicitly programmed. Learning algorithms can be 
supervised or unsupervised. Supervised algorithms learn by example. Unsupervised learning algorithms classify data 
into groups of similar items.

The term “learning” in machine learning is another example of anthropomorphism because the processes of Machine 
Learning are very different to how biological learning takes place. The way neural network models are constructed 
from the patterns in training data is not the same as the way animal brains form new connections whenever they learn 
something new. Machine learning is also computationally intensive and uses vast amounts of electricity.

<a href="mass_media"></a>
### Mass media

Mass media are the *communication industries* which produce *information and entertainment products* and court the 
attention of *large audiences*, which they often sell to *advertisers*. These include broadcasters, networks, 
streaming sites, print and digital publishers and a range of other corporate media producers. This is usually what 
we mean when we talk about “the media”.

<a href="network"></a>
### Network
A network can be defined as any system of relationships ([Chandler & Munday,2020a](/ideas/references/index.html#chandler_munday_2020a))
which may represent relationships between people and things, or between words and other semiotic resources.

<a href="oramedia"></a>
### Oramedia 

Oramedia includes traditionally *oral forms* such as storytelling, proverbs, folklore, folktales, drama, puppetry 
and oral poetry. Digital media are also used to extend the reach of these indigenous forms of communication. 

<a href="media_practices"></a>
### Media practices

Media practices are the activities, habits and routines where people use media (individually or together) as part
of a socially meaningful activity.

<a name="neural_networks"></a> 
### Neural Networks  
A neural network is a statistical data structure based on early ideas about how the human brain works with trillions
of interconnected cells or neurons. The artificial neural network is constructed or “trained” by being fed large 
amounts of data (such as images from a museum gallery website, wikipedia articles, or chat logs). The network 
identifies patterns in the data (such as characteristic uses of colour by a particular artist) and processes them 
to build a mathematical model of an interconnected set of billions or trillions of parameters (numbers). Each 
numerical parameter is called a “neuron”, by analogy to the cellular structures in animal brains. The patterns in 
multidimensional sequences (vectors) of these neurons are used to synthesise media. In the case of generative models 
in LLMs, when a user inputs a text prompt the numbers in the model are used to synthesise a text response which 
conforms to the patterns its vectors have encoded (such as a limerick).  In the case of a text-to-image diffusion 
model it synthesises the pixels of a new image by generating patterns which match the prompt from noise or from 
a seed image.

If a network has not been trained on a specific kind of data, it will not be able to produce that kind of output. 
This is why such models are more likely to reproduce hegemonic discourses and images and are biassed against 
languages and parts of the world which have limited representation online.

When assessing claims about the “intelligence” of AI neural networks, it’s important to realise how simplified 
they are compared to human brains. AI neural networks consist only of interconnected numbers, while a biological 
neural network is far more complex. Animals learn when their neurons build new interconnections with one another 
after repeatedly being exposed to something new. An artificial neuron is a single number while biological neurons 
are highly interlinked chemical systems, communicating with neighbouring neurons and other cells via a variety of 
neurotransmitters.

### Public
Traditionally scholars have talked about "the public", which includes all members of a community such as a nation, city or region, and their legal and political institutions of government.
In media studies it is also common to talk about "publics", which acknowledges that people often have a sense of living, working and communicating together in groups which may be smaller, such as 
a family group chat, or very large, such as a global audience for big media events.

<a name="provenance"></a>
### Provenance
Provenance aims for more transparency regarding the origins and operations of Generative AI.
It responds to the need to know where media and ideas come from, not only to avoid plagiarism, but 
also to be aware of their different contexts of use. Academic referencing is one system of
establishing provenance. Provenance goes beyond the basic information usually included in citations 
(author, date, publisher etc), but also identifies where a media text has "travelled", 
and how it is used in these contexts. This is particularly important for synthetic media and Generative AI, since LLMs 
often don't reveal these details at all. The model's decision-making processes are often not even known by
the programmers of the systems.

We expect media to be created by human beings and organisations who can be held accountable for what they say.
We often can't rely on information produced by Generative AI, as it only represents a likely answer, rather than a verified answer.
Answers always need to be carefully checked and verified against other trustworthy sources.  
(To see the extent to which LLMs are error-prone, see for example this [BBC research into AI assistants](https://www.bbc.co.uk/aboutthebbc/documents/bbc-research-into-ai-assistants.pdf)). 
When evaluating information, we also rely on identifiable sources. Because of the way the training data is encoded in a model, 
is difficult to know who is responsible for media produced by
Generative AI (their [provenance](/ideas/definitions/index.html#provenance)). 
Because we can't easily identify the author or source, we also can't identify bias and don't know whether the original authors of the training data consented to their information or images being used in this way. 


<a name="semiotic_resources"></a>
### Semiotic resources
Semiotic resources are the actions, knowledge and objects which we use for communicative purposes when 
making meaning (semiosis). These include all the physical resources and cultural practices used by humans 
as sign makers. For example, a singer is a sign-maker who makes meaning using their voice, knowledge of a 
musical genre and a spoken language, as well as recording technologies and sharing music via a social platform such as TikTok. 

<a name="social_movement"></a>
### Social movement
A social movement occurs when members of a particular society share grievances such as the experience of oppression, and are motivated to change their society through effective group action. 
Social movements need to recruit others and communicate about their experiences, and they differ depending on the social context and the goals of the movement, which may be revolutionary or reformist, religious or secular and use tactics which are peaceful or violent.


<a name="social_media"></a>
### Social media 

Social media *platforms* bring together *users, content creators and advertisers,* in many cases on a social media
site or app. Platforms represent their users' identities, content, relationships, attention and activities in the 
form of data, which they store, process and trade. Platforms have different functions, but many provide tools and 
functionality for sharing media (text, photos, and videos) with family or friends or for entertainment or professional purposes.

<a name="synthetic_media"></a>
### Synthetic media 

Synthetic media refers to media which has been created or modified by algorithmic (computational) means, 
especially through the use of artificial intelligence (AI) such as Large Language Models (LLMs) 
(e.g. OpenAI's ChatGPT or Google's Gemini). Synthetic media are also known as AI-generated
media, generative media, personalised media or (considerably less positively!) as "**AI sludge**"

<a name="training_data"></a> 
### Training data 
This is the labelled or unlabelled data that is used to create an AI model’s artificial neural network.
A Generative AI model is developed from a very large collection of text and code (the "training data").
The data used to "train" or encode the model is usually billions of words or images "scraped" or copied from the internet
and other sources (often without consent of the original author or artist). 
The scraped training data thus includes a great deal of marketing material, incorrect information (**misinformation**), deliberately
misleading information (**disinformation**) and generally reflects the overall **biases** we tend to find on the Internet and social media sites. 
Unfortunately the raw web data used to train commercial models is loaded with racism, sexism and misinformation, 
and systems trained on such sources may simply reproduce and often exacerbate such biases.


